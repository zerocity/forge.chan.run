[core]
# Executor - CeleryExecutor for distributed task execution
executor = CeleryExecutor

# DAGs folder
dags_folder = /opt/airflow/dags

# Don't load example DAGs
load_examples = False

# Don't pause DAGs on creation
dags_are_paused_at_creation = False
simple_auth_manager_all_admins = "True"

[database]
# Database connection - will be overridden by environment variable
sql_alchemy_conn = postgresql+psycopg2://testuser:testpass@forge-postgres:5432/airflow

[webserver]
# Expose Airflow configuration in the web UI
expose_config = True

# Base URL for the web server
base_url = http://localhost:8080

[scheduler]
# Enable scheduler health check server
enable_health_check = True

[celery]
# Celery broker URL - will be overridden by environment variable
broker_url = redis://:@forge-redis:6379/0

# Celery result backend
result_backend = db+postgresql://testuser:testpass@forge-postgres:5432/airflow

[dag_processor]
# DAG Bundle configuration for Git-based DAG registry
dag_bundle_config_list = [
    {
      "name": "dag_registry",
      "classpath": "airflow.providers.git.bundles.git.GitDagBundle",
      "kwargs": {
        "tracking_ref": "main",
        "git_conn_id": "DAG_REGISTRY",
        "subdir": "dags"
      }
    }
  ]

[logging]
# Logging level
logging_level = INFO

# Base log folder
base_log_folder = /opt/airflow/logs

[api]
# Enable the API
auth_backends = airflow.providers.fab.auth_manager.api.auth.backend.basic_auth

[operators]
# Default owner for DAGs
default_owner = airflow
